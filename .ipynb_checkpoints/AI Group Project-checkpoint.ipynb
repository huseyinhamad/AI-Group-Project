{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf6436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to c:\\users\\husey\\appdata\\local\\temp\\pip-req-build-n0g8nhbp\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages\n",
      "Requirement already satisfied: keras in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-contrib==2.0.8) (2.6.0)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py): started\n",
      "  Building wheel for keras-contrib (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101669 sha256=12d732d15f8a1c634cd528b99c9c91ce5e28ee5e5a1fcf31834d7a679831545f\n",
      "  Stored in directory: C:\\Users\\husey\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-v7694cf_\\wheels\\67\\d2\\f4\\96ae3c3c62d1e05abfc8860ad0c1207794726d44ebbbb547f3\n",
      "Successfully built keras-contrib\n",
      "Requirement already satisfied: opencv-python in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from opencv-python) (1.21.2)\n",
      "Collecting plot_keras_history\n",
      "  Downloading plot_keras_history-1.1.29.tar.gz (9.2 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from plot_keras_history) (3.4.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from plot_keras_history) (1.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from plot_keras_history) (1.7.1)\n",
      "Collecting sanitize_ml_labels\n",
      "  Downloading sanitize_ml_labels-1.0.26.tar.gz (6.4 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (1.21.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas->plot_keras_history) (2021.3)\n",
      "Collecting compress_json\n",
      "  Downloading compress_json-1.0.4.tar.gz (4.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->plot_keras_history) (1.16.0)\n",
      "Building wheels for collected packages: plot-keras-history, sanitize-ml-labels, compress-json\n",
      "  Building wheel for plot-keras-history (setup.py): started\n",
      "  Building wheel for plot-keras-history (setup.py): finished with status 'done'\n",
      "  Created wheel for plot-keras-history: filename=plot_keras_history-1.1.29-py3-none-any.whl size=8613 sha256=f4a8e74c097a424dbd8e0016bc0ff353204b78e1885a11a3eaf95a939122d75b\n",
      "  Stored in directory: c:\\users\\husey\\appdata\\local\\pip\\cache\\wheels\\a0\\fa\\68\\0c3f71f298b99366c7efc3fd98294c58f75b58bd5b91a87eb4\n",
      "  Building wheel for sanitize-ml-labels (setup.py): started\n",
      "  Building wheel for sanitize-ml-labels (setup.py): finished with status 'done'\n",
      "  Created wheel for sanitize-ml-labels: filename=sanitize_ml_labels-1.0.26-py3-none-any.whl size=7612 sha256=78aa6847bcca3efb1df274a05b4e70ab0b6f3bf42e7adc098011a670dabd38a3\n",
      "  Stored in directory: c:\\users\\husey\\appdata\\local\\pip\\cache\\wheels\\d8\\ec\\8b\\d63a91f7060f8b72a790de44492ecf6aee0b5fe1d7b56380be\n",
      "  Building wheel for compress-json (setup.py): started\n",
      "  Building wheel for compress-json (setup.py): finished with status 'done'\n",
      "  Created wheel for compress-json: filename=compress_json-1.0.4-py3-none-any.whl size=4585 sha256=0041492a33891b9e1883b0c11a1ac3066b8891eabb6b9129e2be3224a0ea5146\n",
      "  Stored in directory: c:\\users\\husey\\appdata\\local\\pip\\cache\\wheels\\57\\b7\\6d\\7f4da6ca958ba18b00ea85ba46a5dbfae8f08b992c1466b49b\n",
      "Successfully built plot-keras-history sanitize-ml-labels compress-json\n",
      "Installing collected packages: compress-json, sanitize-ml-labels, plot-keras-history\n",
      "Successfully installed compress-json-1.0.4 plot-keras-history-1.1.29 sanitize-ml-labels-1.0.26\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git \n",
    "!pip install opencv-python\n",
    "!pip install plot_keras_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b0907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Input, Dropout, LeakyReLU, Input, Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization \n",
    "from random import random, randint\n",
    "from plot_keras_history import plot_history\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bef44d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "instance_normalization (Inst (None, 128, 128, 64)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 32, 32, 256)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       4194816   \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 1)         8193      \n",
      "=================================================================\n",
      "Total params: 6,962,497\n",
      "Trainable params: 6,962,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def discriminatorModel(imageShape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=imageShape))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2,2), padding='same',input_shape=imageShape))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, (4, 4), strides=(2,2), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256, (4, 4), strides=(2,2), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, (4, 4), strides=(2,2), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, (4, 4), strides=(1,1), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(1, (4,4)))\n",
    "    # We need to slow down the rate at which the descriminator learns\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'],loss_weights=[0.5])\n",
    "    return model\n",
    "model = discriminatorModel((256,256,3))    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de058ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residualBlock(LNumberofFilters, LInputLayer):\n",
    "    resTensor = Conv2D(LNumberofFilters, (3,3), padding='same')(LInputLayer)\n",
    "    resTensor =InstanceNormalization(axis=-1)(resTensor)\n",
    "    resTensor = Activation('relu')(resTensor)\n",
    "    resTensor = Conv2D(LNumberofFilters, (3,3), padding='same')(resTensor)\n",
    "    resTensor =InstanceNormalization(axis=-1)(resTensor)\n",
    "    resTensor = Concatenate()([resTensor, LInputLayer])\n",
    "    return resTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9bf954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 64) 9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_5 (Insta (None, 256, 256, 64) 128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256, 64) 0           instance_normalization_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 128 73856       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_6 (Insta (None, 128, 128, 128 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 128 0           instance_normalization_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 258)  297474      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, 64, 64, 258)  516         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 258)  0           instance_normalization_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 256)  594688      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, 64, 64, 256)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 256)  0           instance_normalization_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 256)  590080      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, 64, 64, 256)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 514)  0           instance_normalization_9[0][0]   \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  1184512     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, 64, 64, 256)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           instance_normalization_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, 64, 64, 256)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 770)  0           instance_normalization_11[0][0]  \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  1774336     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, 64, 64, 256)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 256)  0           instance_normalization_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, 64, 64, 256)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 1026) 0           instance_normalization_13[0][0]  \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  2364160     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, 64, 64, 256)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, 64, 64, 256)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 1282) 0           instance_normalization_15[0][0]  \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 256)  2953984     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, 64, 64, 256)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, 64, 64, 256)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 1538) 0           instance_normalization_17[0][0]  \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 256)  3543808     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, 64, 64, 256)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 256)  0           instance_normalization_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, 64, 64, 256)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 1794) 0           instance_normalization_19[0][0]  \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 256)  4133632     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, 64, 64, 256)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 256)  0           instance_normalization_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_21 (Inst (None, 64, 64, 256)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 2050) 0           instance_normalization_21[0][0]  \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 256)  4723456     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_22 (Inst (None, 64, 64, 256)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           instance_normalization_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_23 (Inst (None, 64, 64, 256)  512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 2306) 0           instance_normalization_23[0][0]  \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 256)  5313280     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_24 (Inst (None, 64, 64, 256)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 256)  0           instance_normalization_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_25 (Inst (None, 64, 64, 256)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64, 64, 2562) 0           instance_normalization_25[0][0]  \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 128, 128, 128 2951552     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_26 (Inst (None, 128, 128, 128 256         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 256, 64) 73792       instance_normalization_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_27 (Inst (None, 256, 256, 64) 128         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 3)  9411        instance_normalization_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_28 (Inst (None, 256, 256, 3)  6           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 256, 256, 3)  0           instance_normalization_28[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 35,322,639\n",
      "Trainable params: 35,322,639\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generatorModel(LImageShape, LResnet=9):\n",
    "    LInputShape = Input(shape=LImageShape)\n",
    "    genTensor = Conv2D(64, (7,7), padding = 'same',)(LInputShape)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Activation('relu')(genTensor)\n",
    "    genTensor = Conv2D(128, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Activation('relu')(genTensor)\n",
    "    genTensor = Conv2D(258, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Activation('relu')(genTensor)\n",
    "    \n",
    "    for _ in range(LResnet):\n",
    "        genTensor = residualBlock(256, genTensor)\n",
    "    \n",
    "    genTensor = Conv2DTranspose(128, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Conv2DTranspose(64, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Conv2D(3, (7,7), padding='same', activation='tanh')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    \n",
    "    LOutImage = Activation('tanh')(genTensor)\n",
    "    model = Model(LInputShape, LOutImage)\n",
    "    return model\n",
    "\n",
    "model = generatorModel((256,256,3)) \n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d2e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compositeModel(generatorModel1, discriminatorModel, generatorModel2, imageShape):\n",
    "    generatorModel1.trainable = True\n",
    "    discriminatorModel.trainable = False\n",
    "    generatorModel2.trainable = False\n",
    "\n",
    "    InputGenerator = Input(shape=imageShape)\n",
    "    generatorModel1Out = generatorModel1(InputGenerator)\n",
    "    output_d = discriminatorModel(generatorModel1Out)\n",
    "\n",
    "    input_id = Input(shape=imageShape)\n",
    "    output_id = generatorModel1(input_id)\n",
    "\n",
    "    output_f = generatorModel2(generatorModel1Out)\n",
    "    generatorModel2Out = generatorModel2(input_id)\n",
    "    output_b = generatorModel1(generatorModel2Out)\n",
    "\n",
    "    model = Model([InputGenerator, input_id], [output_d, output_id, output_f, output_b])\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf54fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageShape = (256,256,3)\n",
    "generatorModelAtoB = generatorModel(imageShape)\n",
    "generatorModelBtoA = generatorModel(imageShape)\n",
    "discriminatorModelA = discriminatorModel(imageShape)\n",
    "discriminatorModelB = discriminatorModel(imageShape)\n",
    "compositeModelAtoB = compositeModel(generatorModelAtoB, discriminatorModelB, generatorModelBtoA, imageShape)\n",
    "compositeModelBtoA = compositeModel(generatorModelBtoA, discriminatorModelA, generatorModelAtoB, imageShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f54066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRealSamples(dataset, LSamples, patchShape):\n",
    "    ix = np.random.randint(0, dataset.shape[0], LSamples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((LSamples, patchShape, patchShape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c788489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFakeSamples(generatorModel, dataset, patchShape):\n",
    "    X = generatorModel.predict(dataset)\n",
    "    y = np.zeros((len(X), patchShape, patchShape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c14a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            # use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # replace an existing image and use replaced image\n",
    "            ix = randint(0, len(pool) - 1)\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349f0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "    # prepare fake examples\n",
    "    X, _ = generateRealSamples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(10 * 10):\n",
    "        # define subplot\n",
    "        pyplot.subplot(10, 10, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    pyplot.savefig('results_baseline/generated_plot_%03d.png' % (step+1))\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    g_model.save('results_baseline/model_%03d.h5' % (step+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dad5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminatorModelA, discriminatorModelB, generatormodelAtoB, generatormodelBtoA, \n",
    "          compositeModelAtoB, compositeModelBtoA, trainA, trainB):\n",
    "    LEpochs, LBatch = 100, 1\n",
    "    LPatch = discriminatorModelA.output_shape[1]\n",
    "    LBatchPerEpoch = int(len(trainA) / LBatch)\n",
    "    LSteps = LBatchPerEpoch * LEpochs\n",
    "    LPoolA, LPoolB = list(), list()\n",
    "    dA1_hist, dB1_hist, dA2_hist, dB2_hist, g1_hist, g2_hist = list(), list(), list(), list(), list(), list()\n",
    "    for i in range(LSteps):\n",
    "        X_realA, y_realA = generateRealSamples(trainA, LBatch, LPatch)\n",
    "        X_realB, y_realB = generateRealSamples(trainB, LBatch, LPatch)\n",
    "        print(\"Generated Real Samples\")\n",
    "        X_fakeA, y_fakeA = generateFakeSamples(generatormodelBtoA, X_realB, LPatch)\n",
    "        X_fakeB, y_fakeB = generateFakeSamples(generatormodelAtoB, X_realA, LPatch)\n",
    "        print(\"Generated Fake Samples\")\n",
    "        X_fakeA = update_image_pool(LPoolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(LPoolB, X_fakeB)\n",
    "        print(\"Updated Image Pool\")\n",
    "        \n",
    "        gloss2, _, _, _, _  = compositeModelBtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        \n",
    "        dAloss1 = discriminatorModelA.train_on_batch(X_realA, y_realA)\n",
    "        dAloss2 = discriminatorModelA.train_on_batch(X_fakeA, y_fakeA)\n",
    "        \n",
    "        gloss1, _, _, _, _ = compositeModelAtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        \n",
    "        dBloss1 = discriminatorModelA.train_on_batch(X_realB, y_realB)\n",
    "        dBloss2 = discriminatorModelB.train_on_batch(X_fakeB, y_fakeB)\n",
    "        \n",
    "        dA1_hist.append(dAloss1)\n",
    "        dB1_hist.append(dBloss1)\n",
    "        dA2_hist.append(dAloss2)\n",
    "        dB2_hist.append(dBloss2)\n",
    "        g1_hist.append(gloss1)\n",
    "        g2_hist.append(gloss1)\n",
    "        \n",
    "        #if (i+1) % LBatchPerEpoch == 0:\n",
    "         #   summarize_performance(i, generatorModel, 50)\n",
    "    #plot_history(dA1_hist, dB1_hist, dA2_hist, dB2_hist, g1_hist, g2_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73608601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "trainA = []\n",
    "dataset_path = 'images/trainA'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    trainA.append(img)\n",
    "\n",
    "trainB = []\n",
    "dataset_path = 'images/trainB'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    trainB.append(img)\n",
    "\n",
    "testA = []\n",
    "dataset_path = 'images/testA'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    testA.append(img)\n",
    "\n",
    "testB = []\n",
    "dataset_path = 'images/testB'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    testB.append(img)\n",
    "\n",
    "trainA = np.array(trainA)\n",
    "trainB = np.array(trainB)\n",
    "testA = np.array(testA)\n",
    "testB = np.array(testB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aedc623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 55  24  31]\n",
      "   [ 54  26  32]\n",
      "   [ 53  26  30]\n",
      "   ...\n",
      "   [ 49  20  29]\n",
      "   [ 49  20  29]\n",
      "   [ 48  19  28]]\n",
      "\n",
      "  [[ 53  25  31]\n",
      "   [ 54  26  32]\n",
      "   [ 53  26  30]\n",
      "   ...\n",
      "   [ 49  20  29]\n",
      "   [ 49  20  29]\n",
      "   [ 48  19  28]]\n",
      "\n",
      "  [[ 53  25  31]\n",
      "   [ 53  25  31]\n",
      "   [ 52  25  29]\n",
      "   ...\n",
      "   [ 50  21  30]\n",
      "   [ 50  21  30]\n",
      "   [ 49  20  29]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 38  28  41]\n",
      "   [ 35  24  44]\n",
      "   [ 38  29  50]\n",
      "   ...\n",
      "   [ 60  61  89]\n",
      "   [ 60  61  89]\n",
      "   [ 60  61  89]]\n",
      "\n",
      "  [[ 42  31  57]\n",
      "   [ 43  33  56]\n",
      "   [ 43  33  56]\n",
      "   ...\n",
      "   [ 63  63  93]\n",
      "   [ 60  60  90]\n",
      "   [ 61  62  90]]\n",
      "\n",
      "  [[ 36  27  53]\n",
      "   [ 34  25  51]\n",
      "   [ 36  27  53]\n",
      "   ...\n",
      "   [ 62  64  95]\n",
      "   [ 59  59  89]\n",
      "   [ 62  60  90]]]\n",
      "\n",
      "\n",
      " [[[151  79   1]\n",
      "   [159  78   3]\n",
      "   [163  82   1]\n",
      "   ...\n",
      "   [174 215 188]\n",
      "   [173 214 187]\n",
      "   [172 213 186]]\n",
      "\n",
      "  [[154  82   4]\n",
      "   [155  82   2]\n",
      "   [169  83   1]\n",
      "   ...\n",
      "   [172 213 186]\n",
      "   [172 213 186]\n",
      "   [171 212 185]]\n",
      "\n",
      "  [[142  89   8]\n",
      "   [148  86   2]\n",
      "   [164  84   0]\n",
      "   ...\n",
      "   [171 212 185]\n",
      "   [171 212 185]\n",
      "   [170 211 184]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  2 111 143]\n",
      "   [  3  98 131]\n",
      "   [  1  91 122]\n",
      "   ...\n",
      "   [  3  45  74]\n",
      "   [  0  15  22]\n",
      "   [  8  16  29]]\n",
      "\n",
      "  [[  1  94 119]\n",
      "   [  5  97 122]\n",
      "   [  0 107 129]\n",
      "   ...\n",
      "   [  0  85 105]\n",
      "   [  4  54  72]\n",
      "   [  0  22  54]]\n",
      "\n",
      "  [[  3 103 131]\n",
      "   [ 15 108 134]\n",
      "   [  0  98 122]\n",
      "   ...\n",
      "   [  0  68  91]\n",
      "   [  3  47  71]\n",
      "   [  3  43  91]]]\n",
      "\n",
      "\n",
      " [[[ 27  25  37]\n",
      "   [ 30  26  38]\n",
      "   [ 32  26  37]\n",
      "   ...\n",
      "   [ 28  22  33]\n",
      "   [ 28  22  33]\n",
      "   [ 28  22  33]]\n",
      "\n",
      "  [[ 32  30  36]\n",
      "   [ 33  28  37]\n",
      "   [ 33  27  38]\n",
      "   ...\n",
      "   [ 29  23  34]\n",
      "   [ 29  23  34]\n",
      "   [ 29  23  34]]\n",
      "\n",
      "  [[ 31  31  37]\n",
      "   [ 31  28  37]\n",
      "   [ 33  27  38]\n",
      "   ...\n",
      "   [ 31  25  36]\n",
      "   [ 30  25  34]\n",
      "   [ 29  24  33]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  4   9  12]\n",
      "   [  2   5  10]\n",
      "   [ 11  10  19]\n",
      "   ...\n",
      "   [ 26  30  35]\n",
      "   [ 47  51  56]\n",
      "   [ 21  26  29]]\n",
      "\n",
      "  [[  3   6  10]\n",
      "   [  0   1   6]\n",
      "   [  7   6  15]\n",
      "   ...\n",
      "   [ 22  26  31]\n",
      "   [ 38  42  47]\n",
      "   [  5   9  14]]\n",
      "\n",
      "  [[  5   8  12]\n",
      "   [  0   3   8]\n",
      "   [  6   9  14]\n",
      "   ...\n",
      "   [ 13  16  24]\n",
      "   [ 14  18  23]\n",
      "   [  8  12  17]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[165 113  83]\n",
      "   [166 113  86]\n",
      "   [169 114  87]\n",
      "   ...\n",
      "   [160  96  61]\n",
      "   [159  97  57]\n",
      "   [157  96  52]]\n",
      "\n",
      "  [[166 114  84]\n",
      "   [167 114  87]\n",
      "   [170 115  88]\n",
      "   ...\n",
      "   [161  97  62]\n",
      "   [161  99  59]\n",
      "   [159  98  54]]\n",
      "\n",
      "  [[168 116  86]\n",
      "   [168 115  88]\n",
      "   [171 116  89]\n",
      "   ...\n",
      "   [161  98  60]\n",
      "   [162 100  60]\n",
      "   [162 101  57]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99  74  70]\n",
      "   [128  91  93]\n",
      "   [123  82  89]\n",
      "   ...\n",
      "   [142 123 102]\n",
      "   [127 117 107]\n",
      "   [130 108 102]]\n",
      "\n",
      "  [[130 101  97]\n",
      "   [107  82  80]\n",
      "   [107  79  79]\n",
      "   ...\n",
      "   [132  88  71]\n",
      "   [176 135 126]\n",
      "   [133  98  95]]\n",
      "\n",
      "  [[128 100  99]\n",
      "   [ 99  82  79]\n",
      "   [109  90  87]\n",
      "   ...\n",
      "   [130  75  66]\n",
      "   [124  68  57]\n",
      "   [179 142 144]]]\n",
      "\n",
      "\n",
      " [[[178 141 103]\n",
      "   [184 146 111]\n",
      "   [192 155 121]\n",
      "   ...\n",
      "   [226 210 197]\n",
      "   [224 209 200]\n",
      "   [226 210 204]]\n",
      "\n",
      "  [[184 145 107]\n",
      "   [180 142 107]\n",
      "   [183 146 112]\n",
      "   ...\n",
      "   [224 208 195]\n",
      "   [223 208 199]\n",
      "   [221 208 200]]\n",
      "\n",
      "  [[188 146 109]\n",
      "   [181 141 106]\n",
      "   [180 142 108]\n",
      "   ...\n",
      "   [223 206 193]\n",
      "   [224 209 200]\n",
      "   [219 208 200]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[120 148 159]\n",
      "   [102 138 154]\n",
      "   [100 116 132]\n",
      "   ...\n",
      "   [ 57  66  75]\n",
      "   [  0   7  16]\n",
      "   [ 57  62  71]]\n",
      "\n",
      "  [[114 141 155]\n",
      "   [ 99 138 153]\n",
      "   [ 57  79  91]\n",
      "   ...\n",
      "   [  7  16  20]\n",
      "   [ 33  39  46]\n",
      "   [ 39  43  48]]\n",
      "\n",
      "  [[ 70  83  99]\n",
      "   [121 147 164]\n",
      "   [ 69  85  98]\n",
      "   ...\n",
      "   [ 22  29  32]\n",
      "   [ 76  82  87]\n",
      "   [ 67  72  75]]]\n",
      "\n",
      "\n",
      " [[[180 132  96]\n",
      "   [180 132  96]\n",
      "   [180 132  96]\n",
      "   ...\n",
      "   [161 144 165]\n",
      "   [161 144 165]\n",
      "   [164 145 166]]\n",
      "\n",
      "  [[180 132  96]\n",
      "   [180 132  96]\n",
      "   [180 132  96]\n",
      "   ...\n",
      "   [162 145 166]\n",
      "   [164 145 166]\n",
      "   [165 146 167]]\n",
      "\n",
      "  [[180 132  96]\n",
      "   [180 132  96]\n",
      "   [180 132  96]\n",
      "   ...\n",
      "   [164 145 166]\n",
      "   [165 146 167]\n",
      "   [165 146 167]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 27  41  59]\n",
      "   [ 28  42  60]\n",
      "   [ 31  43  61]\n",
      "   ...\n",
      "   [ 15  24  44]\n",
      "   [ 31  39  62]\n",
      "   [ 41  52  72]]\n",
      "\n",
      "  [[ 32  46  64]\n",
      "   [ 28  42  60]\n",
      "   [ 29  43  61]\n",
      "   ...\n",
      "   [ 30  37  57]\n",
      "   [ 31  40  60]\n",
      "   [ 41  51  69]]\n",
      "\n",
      "  [[ 29  45  62]\n",
      "   [ 22  36  54]\n",
      "   [ 25  39  57]\n",
      "   ...\n",
      "   [ 38  45  65]\n",
      "   [ 37  44  64]\n",
      "   [ 45  55  73]]]]\n"
     ]
    }
   ],
   "source": [
    "print(trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2c87bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Real Samples\n",
      "Generated Fake Samples\n",
      "Updated Image Pool\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x00000179032B59D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Given history object of type <class 'list'> is not currently supported!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12068/2644418954.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#TO-DO: IT'S FUCKIN 6 AM AND I CAN'T GET THIS TO WORK. IT SHOULD BE EASY BUT MY STUPID COMPUTER TAKES 1:30 HOUR TO COMPILE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train(discriminatorModelA, discriminatorModelB, generatorModelAtoB, generatorModelBtoA, \n\u001b[0m\u001b[0;32m      3\u001b[0m       compositeModelAtoB, compositeModelBtoA, trainA, trainB)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12068/1673211372.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(discriminatorModelA, discriminatorModelB, generatormodelAtoB, generatormodelBtoA, compositeModelAtoB, compositeModelBtoA, trainA, trainB)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#if (i+1) % LBatchPerEpoch == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m          \u001b[1;31m#   summarize_performance(i, generatorModel, 50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdA1_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdB1_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdA2_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdB2_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg1_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg2_hist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\plot_keras_history\\plot_keras_history.py\u001b[0m in \u001b[0;36mplot_history\u001b[1;34m(histories, style, interpolate, side, graphs_per_row, customization_callback, path, single_graphs, max_epochs, monitor, monitor_mode, log_scale_metrics, title, custom_defaults)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# Normalize the training histories.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     histories = [\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[0mto_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\plot_keras_history\\plot_keras_history.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# Normalize the training histories.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     histories = [\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mto_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     ]\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\plot_keras_history\\utils.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"json\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     raise TypeError(\"Given history object of type {history_type} is not currently supported!\".format(\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mhistory_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     ))\n",
      "\u001b[1;31mTypeError\u001b[0m: Given history object of type <class 'list'> is not currently supported!"
     ]
    }
   ],
   "source": [
    "#TO-DO: IT'S FUCKIN 6 AM AND I CAN'T GET THIS TO WORK. IT SHOULD BE EASY BUT MY STUPID COMPUTER TAKES 1:30 HOUR TO COMPILE\n",
    "train(discriminatorModelA, discriminatorModelB, generatorModelAtoB, generatorModelBtoA, \n",
    "      compositeModelAtoB, compositeModelBtoA, trainA, trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO: Test and generate image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
