{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf6436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to c:\\users\\husey\\appdata\\local\\temp\\pip-req-build-n0g8nhbp\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages\n",
      "Requirement already satisfied: keras in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-contrib==2.0.8) (2.6.0)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py): started\n",
      "  Building wheel for keras-contrib (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101669 sha256=12d732d15f8a1c634cd528b99c9c91ce5e28ee5e5a1fcf31834d7a679831545f\n",
      "  Stored in directory: C:\\Users\\husey\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-v7694cf_\\wheels\\67\\d2\\f4\\96ae3c3c62d1e05abfc8860ad0c1207794726d44ebbbb547f3\n",
      "Successfully built keras-contrib\n",
      "Requirement already satisfied: opencv-python in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from opencv-python) (1.21.2)\n",
      "Collecting plot_keras_history\n",
      "  Downloading plot_keras_history-1.1.29.tar.gz (9.2 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from plot_keras_history) (3.4.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from plot_keras_history) (1.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from plot_keras_history) (1.7.1)\n",
      "Collecting sanitize_ml_labels\n",
      "  Downloading sanitize_ml_labels-1.0.26.tar.gz (6.4 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (1.21.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->plot_keras_history) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas->plot_keras_history) (2021.3)\n",
      "Collecting compress_json\n",
      "  Downloading compress_json-1.0.4.tar.gz (4.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\husey\\anaconda3\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->plot_keras_history) (1.16.0)\n",
      "Building wheels for collected packages: plot-keras-history, sanitize-ml-labels, compress-json\n",
      "  Building wheel for plot-keras-history (setup.py): started\n",
      "  Building wheel for plot-keras-history (setup.py): finished with status 'done'\n",
      "  Created wheel for plot-keras-history: filename=plot_keras_history-1.1.29-py3-none-any.whl size=8613 sha256=f4a8e74c097a424dbd8e0016bc0ff353204b78e1885a11a3eaf95a939122d75b\n",
      "  Stored in directory: c:\\users\\husey\\appdata\\local\\pip\\cache\\wheels\\a0\\fa\\68\\0c3f71f298b99366c7efc3fd98294c58f75b58bd5b91a87eb4\n",
      "  Building wheel for sanitize-ml-labels (setup.py): started\n",
      "  Building wheel for sanitize-ml-labels (setup.py): finished with status 'done'\n",
      "  Created wheel for sanitize-ml-labels: filename=sanitize_ml_labels-1.0.26-py3-none-any.whl size=7612 sha256=78aa6847bcca3efb1df274a05b4e70ab0b6f3bf42e7adc098011a670dabd38a3\n",
      "  Stored in directory: c:\\users\\husey\\appdata\\local\\pip\\cache\\wheels\\d8\\ec\\8b\\d63a91f7060f8b72a790de44492ecf6aee0b5fe1d7b56380be\n",
      "  Building wheel for compress-json (setup.py): started\n",
      "  Building wheel for compress-json (setup.py): finished with status 'done'\n",
      "  Created wheel for compress-json: filename=compress_json-1.0.4-py3-none-any.whl size=4585 sha256=0041492a33891b9e1883b0c11a1ac3066b8891eabb6b9129e2be3224a0ea5146\n",
      "  Stored in directory: c:\\users\\husey\\appdata\\local\\pip\\cache\\wheels\\57\\b7\\6d\\7f4da6ca958ba18b00ea85ba46a5dbfae8f08b992c1466b49b\n",
      "Successfully built plot-keras-history sanitize-ml-labels compress-json\n",
      "Installing collected packages: compress-json, sanitize-ml-labels, plot-keras-history\n",
      "Successfully installed compress-json-1.0.4 plot-keras-history-1.1.29 sanitize-ml-labels-1.0.26\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git \n",
    "!pip install opencv-python\n",
    "!pip install plot_keras_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b0907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Input, Dropout, LeakyReLU, Input, Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization \n",
    "from random import random, randint\n",
    "from plot_keras_history import plot_history\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bef44d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "instance_normalization (Inst (None, 128, 128, 64)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 32, 32, 256)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       4194816   \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 16, 16, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 1)         8193      \n",
      "=================================================================\n",
      "Total params: 6,962,497\n",
      "Trainable params: 6,962,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def discriminatorModel(imageShape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=imageShape))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2,2), padding='same',input_shape=imageShape))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, (4, 4), strides=(2,2), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256, (4, 4), strides=(2,2), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, (4, 4), strides=(2,2), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, (4, 4), strides=(1,1), padding='same'))\n",
    "    model.add(InstanceNormalization(axis=-1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(1, (4,4)))\n",
    "    # We need to slow down the rate at which the descriminator learns\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'],loss_weights=[0.5])\n",
    "    return model\n",
    "model = discriminatorModel((256,256,3))    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de058ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residualBlock(LNumberofFilters, LInputLayer):\n",
    "    resTensor = Conv2D(LNumberofFilters, (3,3), padding='same')(LInputLayer)\n",
    "    resTensor =InstanceNormalization(axis=-1)(resTensor)\n",
    "    resTensor = Activation('relu')(resTensor)\n",
    "    resTensor = Conv2D(LNumberofFilters, (3,3), padding='same')(resTensor)\n",
    "    resTensor =InstanceNormalization(axis=-1)(resTensor)\n",
    "    resTensor = Concatenate()([resTensor, LInputLayer])\n",
    "    return resTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9bf954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 64) 9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_5 (Insta (None, 256, 256, 64) 128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256, 64) 0           instance_normalization_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 128 73856       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_6 (Insta (None, 128, 128, 128 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 128 0           instance_normalization_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 258)  297474      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, 64, 64, 258)  516         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 258)  0           instance_normalization_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 256)  594688      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, 64, 64, 256)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 256)  0           instance_normalization_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 256)  590080      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, 64, 64, 256)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 514)  0           instance_normalization_9[0][0]   \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  1184512     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, 64, 64, 256)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           instance_normalization_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, 64, 64, 256)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 770)  0           instance_normalization_11[0][0]  \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  1774336     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, 64, 64, 256)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 256)  0           instance_normalization_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, 64, 64, 256)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 1026) 0           instance_normalization_13[0][0]  \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  2364160     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, 64, 64, 256)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, 64, 64, 256)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 1282) 0           instance_normalization_15[0][0]  \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 256)  2953984     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, 64, 64, 256)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, 64, 64, 256)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 1538) 0           instance_normalization_17[0][0]  \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 256)  3543808     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, 64, 64, 256)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 256)  0           instance_normalization_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, 64, 64, 256)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 1794) 0           instance_normalization_19[0][0]  \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 256)  4133632     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, 64, 64, 256)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 256)  0           instance_normalization_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_21 (Inst (None, 64, 64, 256)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 2050) 0           instance_normalization_21[0][0]  \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 256)  4723456     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_22 (Inst (None, 64, 64, 256)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           instance_normalization_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_23 (Inst (None, 64, 64, 256)  512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 2306) 0           instance_normalization_23[0][0]  \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 256)  5313280     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_24 (Inst (None, 64, 64, 256)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 256)  0           instance_normalization_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_25 (Inst (None, 64, 64, 256)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64, 64, 2562) 0           instance_normalization_25[0][0]  \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 128, 128, 128 2951552     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_26 (Inst (None, 128, 128, 128 256         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 256, 64) 73792       instance_normalization_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_27 (Inst (None, 256, 256, 64) 128         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 3)  9411        instance_normalization_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_28 (Inst (None, 256, 256, 3)  6           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 256, 256, 3)  0           instance_normalization_28[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 35,322,639\n",
      "Trainable params: 35,322,639\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generatorModel(LImageShape, LResnet=9):\n",
    "    LInputShape = Input(shape=LImageShape)\n",
    "    genTensor = Conv2D(64, (7,7), padding = 'same',)(LInputShape)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Activation('relu')(genTensor)\n",
    "    genTensor = Conv2D(128, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Activation('relu')(genTensor)\n",
    "    genTensor = Conv2D(258, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Activation('relu')(genTensor)\n",
    "    \n",
    "    for _ in range(LResnet):\n",
    "        genTensor = residualBlock(256, genTensor)\n",
    "    \n",
    "    genTensor = Conv2DTranspose(128, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Conv2DTranspose(64, (3,3), strides = (2,2), padding = 'same')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    genTensor = Conv2D(3, (7,7), padding='same', activation='tanh')(genTensor)\n",
    "    genTensor = InstanceNormalization(axis=-1)(genTensor)\n",
    "    \n",
    "    LOutImage = Activation('tanh')(genTensor)\n",
    "    model = Model(LInputShape, LOutImage)\n",
    "    return model\n",
    "\n",
    "model = generatorModel((256,256,3)) \n",
    "model.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d2e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compositeModel(generatorModel1, discriminatorModel, generatorModel2, imageShape):\n",
    "    generatorModel1.trainable = True\n",
    "    discriminatorModel.trainable = False\n",
    "    generatorModel2.trainable = False\n",
    "\n",
    "    InputGenerator = Input(shape=imageShape)\n",
    "    generatorModel1Out = generatorModel1(InputGenerator)\n",
    "    output_d = discriminatorModel(generatorModel1Out)\n",
    "\n",
    "    input_id = Input(shape=imageShape)\n",
    "    output_id = generatorModel1(input_id)\n",
    "\n",
    "    output_f = generatorModel2(generatorModel1Out)\n",
    "    generatorModel2Out = generatorModel2(input_id)\n",
    "    output_b = generatorModel1(generatorModel2Out)\n",
    "\n",
    "    model = Model([InputGenerator, input_id], [output_d, output_id, output_f, output_b])\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf54fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageShape = (256,256,3)\n",
    "generatorModelAtoB = generatorModel(imageShape)\n",
    "generatorModelBtoA = generatorModel(imageShape)\n",
    "discriminatorModelA = discriminatorModel(imageShape)\n",
    "discriminatorModelB = discriminatorModel(imageShape)\n",
    "compositeModelAtoB = compositeModel(generatorModelAtoB, discriminatorModelB, generatorModelBtoA, imageShape)\n",
    "compositeModelBtoA = compositeModel(generatorModelBtoA, discriminatorModelA, generatorModelAtoB, imageShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f54066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRealSamples(dataset, LSamples, patchShape):\n",
    "    ix = np.random.randint(0, dataset.shape[0], LSamples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((LSamples, patchShape, patchShape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c788489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFakeSamples(generatorModel, dataset, patchShape):\n",
    "    X = generatorModel.predict(dataset)\n",
    "    y = np.zeros((len(X), patchShape, patchShape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c14a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random() < 0.5:\n",
    "            # use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # replace an existing image and use replaced image\n",
    "            ix = randint(0, len(pool) - 1)\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349f0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "    # prepare fake examples\n",
    "    X, _ = generateRealSamples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(10 * 10):\n",
    "        # define subplot\n",
    "        pyplot.subplot(10, 10, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    pyplot.savefig('results_baseline/generated_plot_%03d.png' % (step+1))\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    g_model.save('results_baseline/model_%03d.h5' % (step+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dad5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(discriminatorModelA, discriminatorModelB, generatormodelAtoB, generatormodelBtoA, \n",
    "          compositeModelAtoB, compositeModelBtoA, trainA, trainB):\n",
    "    LEpochs, LBatch = 100, 1\n",
    "    LPatch = discriminatorModelA.output_shape[1]\n",
    "    LBatchPerEpoch = int(len(trainA) / LBatch)\n",
    "    #LSteps = LBatchPerEpoch * LEpochs\n",
    "    LSteps = 5\n",
    "    LPoolA, LPoolB = list(), list()\n",
    "    dA1_hist, dB1_hist, dA2_hist, dB2_hist, g1_hist, g2_hist = list(), list(), list(), list(), list(), list()\n",
    "    for i in range(LSteps):\n",
    "        X_realA, y_realA = generateRealSamples(trainA, LBatch, LPatch)\n",
    "        X_realB, y_realB = generateRealSamples(trainB, LBatch, LPatch)\n",
    "        print(\"Generated Real Samples\")\n",
    "        X_fakeA, y_fakeA = generateFakeSamples(generatormodelBtoA, X_realB, LPatch)\n",
    "        X_fakeB, y_fakeB = generateFakeSamples(generatormodelAtoB, X_realA, LPatch)\n",
    "        print(\"Generated Fake Samples\")\n",
    "        X_fakeA = update_image_pool(LPoolA, X_fakeA)\n",
    "        X_fakeB = update_image_pool(LPoolB, X_fakeB)\n",
    "        print(\"Updated Image Pool\")\n",
    "        \n",
    "        gloss2, _, _, _, _  = compositeModelBtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "        \n",
    "        dAloss1 = discriminatorModelA.train_on_batch(X_realA, y_realA)\n",
    "        dAloss2 = discriminatorModelA.train_on_batch(X_fakeA, y_fakeA)\n",
    "        \n",
    "        gloss1, _, _, _, _ = compositeModelAtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "        print(\"Calculated Generator Loss\")\n",
    "        \n",
    "        dBloss1 = discriminatorModelA.train_on_batch(X_realB, y_realB)\n",
    "        dBloss2 = discriminatorModelB.train_on_batch(X_fakeB, y_fakeB)\n",
    "        print(\"Calculated Discriminator Loss\")\n",
    "        \n",
    "        dA1_hist.append(dAloss1)\n",
    "        dB1_hist.append(dBloss1)\n",
    "        dA2_hist.append(dAloss2)\n",
    "        dB2_hist.append(dBloss2)\n",
    "        g1_hist.append(gloss1)\n",
    "        g2_hist.append(gloss1)\n",
    "        \n",
    "        print(\"Finished\")\n",
    "        \n",
    "        generatormodelAtoB.save('results_baseline/model_%03d.h5' % (step+1))\n",
    "        #if (i+1) % LBatchPerEpoch == 0:\n",
    "         #   summarize_performance(i, generatorModel, 50)\n",
    "    #plot_history(dA1_hist, dB1_hist, dA2_hist, dB2_hist, g1_hist, g2_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73608601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "trainA = []\n",
    "dataset_path = 'images/trainA'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    trainA.append(img)\n",
    "\n",
    "trainB = []\n",
    "dataset_path = 'images/trainB'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    trainB.append(img)\n",
    "\n",
    "testA = []\n",
    "dataset_path = 'images/testA'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    testA.append(img)\n",
    "\n",
    "testB = []\n",
    "dataset_path = 'images/testB'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    testB.append(img)\n",
    "\n",
    "trainA = np.array(trainA)\n",
    "trainB = np.array(trainB)\n",
    "testA = np.array(testA)\n",
    "testB = np.array(testB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "440fa416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 55  24  31]\n",
      "   [ 54  26  32]\n",
      "   [ 53  26  30]\n",
      "   ...\n",
      "   [ 49  20  29]\n",
      "   [ 49  20  29]\n",
      "   [ 48  19  28]]\n",
      "\n",
      "  [[ 53  25  31]\n",
      "   [ 54  26  32]\n",
      "   [ 53  26  30]\n",
      "   ...\n",
      "   [ 49  20  29]\n",
      "   [ 49  20  29]\n",
      "   [ 48  19  28]]\n",
      "\n",
      "  [[ 53  25  31]\n",
      "   [ 53  25  31]\n",
      "   [ 52  25  29]\n",
      "   ...\n",
      "   [ 50  21  30]\n",
      "   [ 50  21  30]\n",
      "   [ 49  20  29]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 38  28  41]\n",
      "   [ 35  24  44]\n",
      "   [ 38  29  50]\n",
      "   ...\n",
      "   [ 60  61  89]\n",
      "   [ 60  61  89]\n",
      "   [ 60  61  89]]\n",
      "\n",
      "  [[ 42  31  57]\n",
      "   [ 43  33  56]\n",
      "   [ 43  33  56]\n",
      "   ...\n",
      "   [ 63  63  93]\n",
      "   [ 60  60  90]\n",
      "   [ 61  62  90]]\n",
      "\n",
      "  [[ 36  27  53]\n",
      "   [ 34  25  51]\n",
      "   [ 36  27  53]\n",
      "   ...\n",
      "   [ 62  64  95]\n",
      "   [ 59  59  89]\n",
      "   [ 62  60  90]]]\n",
      "\n",
      "\n",
      " [[[151  79   1]\n",
      "   [159  78   3]\n",
      "   [163  82   1]\n",
      "   ...\n",
      "   [174 215 188]\n",
      "   [173 214 187]\n",
      "   [172 213 186]]\n",
      "\n",
      "  [[154  82   4]\n",
      "   [155  82   2]\n",
      "   [169  83   1]\n",
      "   ...\n",
      "   [172 213 186]\n",
      "   [172 213 186]\n",
      "   [171 212 185]]\n",
      "\n",
      "  [[142  89   8]\n",
      "   [148  86   2]\n",
      "   [164  84   0]\n",
      "   ...\n",
      "   [171 212 185]\n",
      "   [171 212 185]\n",
      "   [170 211 184]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  2 111 143]\n",
      "   [  3  98 131]\n",
      "   [  1  91 122]\n",
      "   ...\n",
      "   [  3  45  74]\n",
      "   [  0  15  22]\n",
      "   [  8  16  29]]\n",
      "\n",
      "  [[  1  94 119]\n",
      "   [  5  97 122]\n",
      "   [  0 107 129]\n",
      "   ...\n",
      "   [  0  85 105]\n",
      "   [  4  54  72]\n",
      "   [  0  22  54]]\n",
      "\n",
      "  [[  3 103 131]\n",
      "   [ 15 108 134]\n",
      "   [  0  98 122]\n",
      "   ...\n",
      "   [  0  68  91]\n",
      "   [  3  47  71]\n",
      "   [  3  43  91]]]\n",
      "\n",
      "\n",
      " [[[ 27  25  37]\n",
      "   [ 30  26  38]\n",
      "   [ 32  26  37]\n",
      "   ...\n",
      "   [ 28  22  33]\n",
      "   [ 28  22  33]\n",
      "   [ 28  22  33]]\n",
      "\n",
      "  [[ 32  30  36]\n",
      "   [ 33  28  37]\n",
      "   [ 33  27  38]\n",
      "   ...\n",
      "   [ 29  23  34]\n",
      "   [ 29  23  34]\n",
      "   [ 29  23  34]]\n",
      "\n",
      "  [[ 31  31  37]\n",
      "   [ 31  28  37]\n",
      "   [ 33  27  38]\n",
      "   ...\n",
      "   [ 31  25  36]\n",
      "   [ 30  25  34]\n",
      "   [ 29  24  33]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  4   9  12]\n",
      "   [  2   5  10]\n",
      "   [ 11  10  19]\n",
      "   ...\n",
      "   [ 26  30  35]\n",
      "   [ 47  51  56]\n",
      "   [ 21  26  29]]\n",
      "\n",
      "  [[  3   6  10]\n",
      "   [  0   1   6]\n",
      "   [  7   6  15]\n",
      "   ...\n",
      "   [ 22  26  31]\n",
      "   [ 38  42  47]\n",
      "   [  5   9  14]]\n",
      "\n",
      "  [[  5   8  12]\n",
      "   [  0   3   8]\n",
      "   [  6   9  14]\n",
      "   ...\n",
      "   [ 13  16  24]\n",
      "   [ 14  18  23]\n",
      "   [  8  12  17]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[165 113  83]\n",
      "   [166 113  86]\n",
      "   [169 114  87]\n",
      "   ...\n",
      "   [160  96  61]\n",
      "   [159  97  57]\n",
      "   [157  96  52]]\n",
      "\n",
      "  [[166 114  84]\n",
      "   [167 114  87]\n",
      "   [170 115  88]\n",
      "   ...\n",
      "   [161  97  62]\n",
      "   [161  99  59]\n",
      "   [159  98  54]]\n",
      "\n",
      "  [[168 116  86]\n",
      "   [168 115  88]\n",
      "   [171 116  89]\n",
      "   ...\n",
      "   [161  98  60]\n",
      "   [162 100  60]\n",
      "   [162 101  57]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 99  74  70]\n",
      "   [128  91  93]\n",
      "   [123  82  89]\n",
      "   ...\n",
      "   [142 123 102]\n",
      "   [127 117 107]\n",
      "   [130 108 102]]\n",
      "\n",
      "  [[130 101  97]\n",
      "   [107  82  80]\n",
      "   [107  79  79]\n",
      "   ...\n",
      "   [132  88  71]\n",
      "   [176 135 126]\n",
      "   [133  98  95]]\n",
      "\n",
      "  [[128 100  99]\n",
      "   [ 99  82  79]\n",
      "   [109  90  87]\n",
      "   ...\n",
      "   [130  75  66]\n",
      "   [124  68  57]\n",
      "   [179 142 144]]]\n",
      "\n",
      "\n",
      " [[[178 141 103]\n",
      "   [184 146 111]\n",
      "   [192 155 121]\n",
      "   ...\n",
      "   [226 210 197]\n",
      "   [224 209 200]\n",
      "   [226 210 204]]\n",
      "\n",
      "  [[184 145 107]\n",
      "   [180 142 107]\n",
      "   [183 146 112]\n",
      "   ...\n",
      "   [224 208 195]\n",
      "   [223 208 199]\n",
      "   [221 208 200]]\n",
      "\n",
      "  [[188 146 109]\n",
      "   [181 141 106]\n",
      "   [180 142 108]\n",
      "   ...\n",
      "   [223 206 193]\n",
      "   [224 209 200]\n",
      "   [219 208 200]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[120 148 159]\n",
      "   [102 138 154]\n",
      "   [100 116 132]\n",
      "   ...\n",
      "   [ 57  66  75]\n",
      "   [  0   7  16]\n",
      "   [ 57  62  71]]\n",
      "\n",
      "  [[114 141 155]\n",
      "   [ 99 138 153]\n",
      "   [ 57  79  91]\n",
      "   ...\n",
      "   [  7  16  20]\n",
      "   [ 33  39  46]\n",
      "   [ 39  43  48]]\n",
      "\n",
      "  [[ 70  83  99]\n",
      "   [121 147 164]\n",
      "   [ 69  85  98]\n",
      "   ...\n",
      "   [ 22  29  32]\n",
      "   [ 76  82  87]\n",
      "   [ 67  72  75]]]\n",
      "\n",
      "\n",
      " [[[180 132  96]\n",
      "   [180 132  96]\n",
      "   [180 132  96]\n",
      "   ...\n",
      "   [161 144 165]\n",
      "   [161 144 165]\n",
      "   [164 145 166]]\n",
      "\n",
      "  [[180 132  96]\n",
      "   [180 132  96]\n",
      "   [180 132  96]\n",
      "   ...\n",
      "   [162 145 166]\n",
      "   [164 145 166]\n",
      "   [165 146 167]]\n",
      "\n",
      "  [[180 132  96]\n",
      "   [180 132  96]\n",
      "   [180 132  96]\n",
      "   ...\n",
      "   [164 145 166]\n",
      "   [165 146 167]\n",
      "   [165 146 167]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 27  41  59]\n",
      "   [ 28  42  60]\n",
      "   [ 31  43  61]\n",
      "   ...\n",
      "   [ 15  24  44]\n",
      "   [ 31  39  62]\n",
      "   [ 41  52  72]]\n",
      "\n",
      "  [[ 32  46  64]\n",
      "   [ 28  42  60]\n",
      "   [ 29  43  61]\n",
      "   ...\n",
      "   [ 30  37  57]\n",
      "   [ 31  40  60]\n",
      "   [ 41  51  69]]\n",
      "\n",
      "  [[ 29  45  62]\n",
      "   [ 22  36  54]\n",
      "   [ 25  39  57]\n",
      "   ...\n",
      "   [ 38  45  65]\n",
      "   [ 37  44  64]\n",
      "   [ 45  55  73]]]]\n"
     ]
    }
   ],
   "source": [
    "print(trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c87bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Real Samples\n",
      "Generated Fake Samples\n",
      "Updated Image Pool\n",
      "Calculated Generator Loss\n",
      "Calculated Discriminator Loss\n",
      "Finished\n",
      "Generated Real Samples\n",
      "Generated Fake Samples\n",
      "Updated Image Pool\n",
      "Calculated Generator Loss\n",
      "Calculated Discriminator Loss\n",
      "Finished\n",
      "Generated Real Samples\n",
      "Generated Fake Samples\n",
      "Updated Image Pool\n",
      "Calculated Generator Loss\n",
      "Calculated Discriminator Loss\n",
      "Finished\n",
      "Generated Real Samples\n",
      "Generated Fake Samples\n",
      "Updated Image Pool\n",
      "Calculated Generator Loss\n",
      "Calculated Discriminator Loss\n",
      "Finished\n",
      "Generated Real Samples\n",
      "Generated Fake Samples\n",
      "Updated Image Pool\n",
      "Calculated Generator Loss\n",
      "Calculated Discriminator Loss\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#TO-DO: IT'S FUCKIN 6 AM AND I CAN'T GET THIS TO WORK. IT SHOULD BE EASY BUT MY STUPID COMPUTER TAKES 1:30 HOUR TO COMPILE\n",
    "train(discriminatorModelA, discriminatorModelB, generatorModelAtoB, generatorModelBtoA, \n",
    "      compositeModelAtoB, compositeModelBtoA, trainA, trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7c333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO: Test and generate image\n",
    "testA = []\n",
    "dataset_path = 'images/testA'\n",
    "for filename in os.listdir(dataset_path):\n",
    "    img = cv2.imread(os.path.join(dataset_path, filename))\n",
    "    testA.append(img)\n",
    "    break\n",
    "    \n",
    "testA = np.array(testA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95b06c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12068/3129469052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RGB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "(X, y) = generateFakeSamples(generatorModelAtoB, testA, discriminatorModelA.output_shape[1])\n",
    "import PIL \n",
    "from PIL import Image\n",
    "X = X.reshape((X.shape[1], X.shape[2], img.shape[3]))\n",
    "image = PIL.Image.fromarray(X, \"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab67fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f474f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
